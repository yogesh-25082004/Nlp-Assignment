{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac6a3e7b-228c-4dab-be48-3653f3a3c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Comment', 'Sentiment'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 1.1805\n",
      "Epoch 10 - Loss: 1.1656\n",
      "Epoch 20 - Loss: 1.1459\n",
      "Epoch 30 - Loss: 1.1247\n",
      "Epoch 40 - Loss: 1.0975\n",
      "\n",
      "✅ Test Accuracy: 0.70\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# STEP 1: Load Dataset from Local File\n",
    "file_path = \"C:\\\\Users\\\\Admin\\\\Downloads\\\\YoutubeCommentsDataSet.csv\"  # Path to your downloaded file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# STEP 2: Inspect the columns to find the correct column for comments\n",
    "print(df.columns)\n",
    "\n",
    "# STEP 3: Clean the Comments\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)  # Remove non-alphabetical characters\n",
    "    return text.lower().strip()  # Convert to lowercase and remove leading/trailing spaces\n",
    "\n",
    "# Apply the clean_text function to the 'Comment' column\n",
    "df['cleaned_comment'] = df['Comment'].apply(clean_text)\n",
    "\n",
    "# STEP 4: Run Sentiment Analysis using BERT\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Mapping of BERT output to three labels (Positive, Negative, Neutral)\n",
    "sentiments = []\n",
    "for comment in df['cleaned_comment'].dropna().tolist()[:100]:  # Limit to 100 for performance\n",
    "    result = sentiment_pipeline(comment)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    \n",
    "    if label == 'LABEL_0':  # Negative sentiment\n",
    "        sentiment = 0  # Negative\n",
    "    elif label == 'LABEL_1':  # Neutral sentiment\n",
    "        sentiment = 1  # Neutral\n",
    "    else:  # Positive sentiment\n",
    "        sentiment = 2  # Positive\n",
    "    \n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "sentiment_df = pd.DataFrame({\n",
    "    'comment': df['cleaned_comment'].dropna().tolist()[:100],\n",
    "    'sentiment_score': sentiments\n",
    "})\n",
    "\n",
    "# STEP 5: Simulate QoS Features\n",
    "np.random.seed(42)\n",
    "n = len(sentiment_df)\n",
    "qos_data = pd.DataFrame({\n",
    "    'bitrate': np.random.randint(1000, 4000, size=n),\n",
    "    'buffering': np.random.uniform(0.2, 3.0, size=n),\n",
    "    'resolution': np.random.choice([480, 720, 1080], size=n),\n",
    "    'viewers': np.random.randint(100, 5000, size=n),\n",
    "})\n",
    "\n",
    "# Combine with sentiment scores\n",
    "final_data = pd.concat([qos_data.reset_index(drop=True), sentiment_df['sentiment_score']], axis=1)\n",
    "\n",
    "# STEP 6: Prepare Data for Training (Handling three classes)\n",
    "labels = sentiment_df['sentiment_score']  # This is now a 3-class label\n",
    "\n",
    "# STEP 7: Prepare Data for Neural Network\n",
    "X = final_data\n",
    "y = labels\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)  # Change to long for multi-class classification\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)  # Change to long for multi-class classification\n",
    "\n",
    "# STEP 8: Define Deep Neural Network Model for Multi-Class Classification\n",
    "class SatisfactionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SatisfactionModel, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 3),  # Output 3 classes (for Positive, Negative, Neutral)\n",
    "            nn.Softmax(dim=1)  # Softmax for multi-class classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = SatisfactionModel(input_dim=X.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()  # Using CrossEntropyLoss for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# STEP 9: Train the Model\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "# STEP 10: Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor).argmax(dim=1)  # Use argmax to get the predicted class\n",
    "    accuracy = (predictions == y_test_tensor).float().mean()\n",
    "    print(f\"\\n✅ Test Accuracy: {accuracy.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ce7a9d6-58c8-46c4-af21-87df97b5e7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'sentiment_model.pth')  # Save model weights\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58fa5b21-1ba4-471c-b3d4-e02a05f3bb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# STEP 12: Load the Saved Model\n",
    "# Reinitialize the model\n",
    "model = SatisfactionModel(input_dim=X.shape[1])\n",
    "\n",
    "# Load the saved weights\n",
    "model.load_state_dict(torch.load('sentiment_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2fe3763-6e2f-4bf7-83f3-623123ad5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Negative with confidence score: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment_with_model(comment):\n",
    "    # Clean the new comment\n",
    "    cleaned_comment = clean_text(comment)\n",
    "    \n",
    "    # Use the BERT model for sentiment analysis (for comment sentiment score)\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "    result = sentiment_pipeline(cleaned_comment)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    \n",
    "    # Map BERT output to sentiment label\n",
    "    if label == \"POSITIVE\":\n",
    "        sentiment_score = 2  # Positive\n",
    "    elif label == \"NEGATIVE\":\n",
    "        sentiment_score = 0  # Negative\n",
    "    else:\n",
    "        sentiment_score = 1  # Neutral\n",
    "    \n",
    "    # Simulate QoS data for the new comment (or replace with real QoS data)\n",
    "    qos_test_data = np.random.rand(1, 4)  # Assuming 4 features like bitrate, buffering, resolution, viewers\n",
    "    \n",
    "    # Add the sentiment score as a new feature\n",
    "    qos_test_data_with_sentiment = np.hstack([qos_test_data, np.array([[sentiment_score]])])  # Adding sentiment score\n",
    "    \n",
    "    # Use the same scaler as during training\n",
    "    qos_test_data_with_sentiment = scaler.transform(qos_test_data_with_sentiment)  # Now we have 5 features\n",
    "    \n",
    "    # Convert to torch tensor\n",
    "    input_tensor = torch.tensor(qos_test_data_with_sentiment, dtype=torch.float32)\n",
    "    \n",
    "    # Get prediction from the trained model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        predicted_class = output.argmax(dim=1).item()  # Get the class with the highest probability\n",
    "    \n",
    "    # Map predicted class to the corresponding sentiment label\n",
    "    sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "    predicted_sentiment = sentiment_labels[predicted_class]\n",
    "    \n",
    "    return predicted_sentiment, score\n",
    "\n",
    "# Example usage for prediction:\n",
    "new_comment = \"I didn't like this movie\"\n",
    "predicted_sentiment, score = predict_sentiment_with_model(new_comment)\n",
    "print(f\"Predicted Sentiment: {predicted_sentiment} with confidence score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1264977-fd0e-4c40-9473-714e1b20df1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
